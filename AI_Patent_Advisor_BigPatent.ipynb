{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c56e0caf-1680-4f23-9c87-5d4c8b4ab170",
      "metadata": {
        "id": "c56e0caf-1680-4f23-9c87-5d4c8b4ab170"
      },
      "source": [
        "# App: AI Patent Advisor\n",
        "### Dataset: BigPatent (https://huggingface.co/datasets/NortheasternUniversity/big_patent)\n",
        "\n",
        "### Features:\n",
        "**Simplified Prior Art Search:** Instead of complex keyword searches, users can describe their invention in natural language. A RAG system retrieves relevant patents from BigPatent based on semantic similarity and provides them as context to an LLM. A prompt like, \"Given this invention description [user input] and these similar patents [retrieved patents], summarize the most relevant prior art and potential novelty issues\" can generate a concise report. This simplifies the search process and makes it accessible to non-patent experts.\n",
        "\n",
        "**Competitive Technology Monitoring:** Users define a specific technology area or competitor. The system automatically retrieves newly published patents from BigPatent within that domain. A prompt such as, \"Summarize the key innovations disclosed in these recently published patents [retrieved patents] related to [technology area/competitor]\" provides a quick overview of competitive activity.\n",
        "\n",
        "**Patent Claim Analysis & Comparison:** Input two or more patent claims. The system retrieves relevant contextual information from the full patent text within BigPatent. A prompt like, \"Compare and contrast the scope of these patent claims [input claims] considering their full patent specifications [retrieved patent text]. Identify key differences and potential areas of overlap\" facilitates detailed claim analysis.\n",
        "\n",
        "**Automated Patent Summary Generation:** Input a full patent text. The system uses a prompt like, \"Generate a concise, non-legal summary of this patent [input patent] highlighting the key innovation and potential applications.\" This quickly generates summaries suitable for business audiences or technical teams, saving time and resources.\n",
        "\n",
        "**Patent Landscape Overview by CPC Class:** Users specify a CPC classification code. The system retrieves a sample of patents from BigPatent within that class. A prompt like, \"Based on these patents [retrieved patents] within CPC class [input code], summarize the current state of the art, key players, and emerging trends\" provides a quick overview of a specific technology domain. The structured nature of CPC codes simplifies retrieval and analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76650cc3-8eaf-4a2d-9d7d-ecfe0d2c29a5",
      "metadata": {
        "id": "76650cc3-8eaf-4a2d-9d7d-ecfe0d2c29a5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"False\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9149a68d-faad-4778-912b-e9939d4a3709",
      "metadata": {
        "id": "9149a68d-faad-4778-912b-e9939d4a3709"
      },
      "outputs": [],
      "source": [
        "!pip -q install gradio datasets transformers langchain faiss-cpu sentence_transformers langchain-community openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9701e800-6717-4485-89e5-8c6aec32418f",
      "metadata": {
        "id": "9701e800-6717-4485-89e5-8c6aec32418f"
      },
      "outputs": [],
      "source": [
        "!pip -q install bert_score\n",
        "!pip -q install langchain_openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb7f812b-2064-466a-a210-aa3f716737b6",
      "metadata": {
        "id": "bb7f812b-2064-466a-a210-aa3f716737b6"
      },
      "outputs": [],
      "source": [
        "!pip -q install tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "710495b4-39d8-40d9-9416-3e50ddf4dbe7",
      "metadata": {
        "id": "710495b4-39d8-40d9-9416-3e50ddf4dbe7"
      },
      "outputs": [],
      "source": [
        "!pip -q install -U langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97bdd801-f3ea-45df-8dd5-48471cdc9210",
      "metadata": {
        "id": "97bdd801-f3ea-45df-8dd5-48471cdc9210"
      },
      "outputs": [],
      "source": [
        "!pip -q install pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe5887c8-ec06-4b75-8081-6cf4ff198a02",
      "metadata": {
        "id": "fe5887c8-ec06-4b75-8081-6cf4ff198a02"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "from datasets import load_dataset\n",
        "from transformers import pipeline\n",
        "from langchain.embeddings import HuggingFaceEmbeddings, SentenceTransformerEmbeddings\n",
        "#from langchain_community.embeddings import SentenceTransformerEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.memory import ConversationBufferWindowMemory\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "import os\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from tqdm import tqdm\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "febc3a24-741e-47ca-9196-05739741ff93",
      "metadata": {
        "id": "febc3a24-741e-47ca-9196-05739741ff93"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "# Hugging face API Token\n",
        "HUGGINGFACEHUB_API_TOKEN = userdata.get('HF_KEY')\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = HUGGINGFACEHUB_API_TOKEN\n",
        "os.environ[\"HF_TOKEN\"] = HUGGINGFACEHUB_API_TOKEN\n",
        "# OpenAI API key\n",
        "OPENAI_API_KEY = userdata.get('OPENAI_KEY')\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27feb74e-97a1-427c-9187-79f94f24917e",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "ad23fe2b695346128b612e2a7c5c7fc2",
            "afc4c93ae43a40bfac0f7094f40ea042"
          ]
        },
        "id": "27feb74e-97a1-427c-9187-79f94f24917e",
        "outputId": "4f5d6257-a797-4803-c27b-0c51801efcc6"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ad23fe2b695346128b612e2a7c5c7fc2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md:   0%|          | 0.00/9.71k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "afc4c93ae43a40bfac0f7094f40ea042",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "big_patent.py:   0%|          | 0.00/5.50k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Load a smaller subset of the 'g' CPC code patents for initial development (100 samples)\n",
        "dataset = load_dataset(\"big_patent\", \"g\", trust_remote_code=True, split=\"train[:100]\")\n",
        "texts = dataset[\"description\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e6131cd-54b8-40ff-ae1a-048251c8d16f",
      "metadata": {
        "id": "7e6131cd-54b8-40ff-ae1a-048251c8d16f"
      },
      "outputs": [],
      "source": [
        "! rm -rf .cache/huggingface/hub/datasets--big_patent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1f16962-e3cd-4125-80e6-a082c378c46b",
      "metadata": {
        "id": "c1f16962-e3cd-4125-80e6-a082c378c46b"
      },
      "outputs": [],
      "source": [
        "#embeddings = SentenceTransformerEmbeddings(model_name='allenai-specter')  # Make sure to install sentence-transformers\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ab68edb-84d7-4842-ad9d-dd3c1d4d4376",
      "metadata": {
        "id": "0ab68edb-84d7-4842-ad9d-dd3c1d4d4376",
        "outputId": "85be4489-d76a-4c8d-8f9f-ae1b6f158e7b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Creating chunks: 100%|██████████| 100/100 [00:00<00:00, 205.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FAISS VectorDB created with 8843 vectors.\n"
          ]
        }
      ],
      "source": [
        "def create_vectordb(texts, chunk_size=500, chunk_overlap=50):\n",
        "    text_splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=chunk_size, chunk_overlap=chunk_overlap\n",
        "    )\n",
        "    docs = []\n",
        "    for text in tqdm(texts, desc=\"Creating chunks\"):\n",
        "        chunks = text_splitter.split_text(text)\n",
        "        docs.extend(chunks)\n",
        "\n",
        "    # Initialize embeddings (assuming 'embeddings' is already defined as HuggingFaceEmbeddings)\n",
        "    db = FAISS.from_texts(docs, embeddings)\n",
        "    return db\n",
        "\n",
        "# Example usage (assuming 'texts' is already defined):\n",
        "db = create_vectordb(texts)\n",
        "print(f\"FAISS VectorDB created with {len(db.index_to_docstore_id)} vectors.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64030cbe-fca8-4909-a73c-990a98713d5c",
      "metadata": {
        "id": "64030cbe-fca8-4909-a73c-990a98713d5c"
      },
      "outputs": [],
      "source": [
        "# prompt: write python code to save the vectordb. Then load it for use\n",
        "\n",
        "# import pickle\n",
        "\n",
        "# # Save the vector database to a file\n",
        "# with open(\"vector_db.pkl\", \"wb\") as f:\n",
        "#     pickle.dump(db, f)\n",
        "\n",
        "# # Load the vector database from the file\n",
        "# with open(\"vector_db.pkl\", \"rb\") as f:\n",
        "#     loaded_db = pickle.load(f)\n",
        "\n",
        "#print(f\"Loaded FAISS index with {len(loaded_db.index_to_docstore_id)} vectors.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a3d01a3-02fe-47fc-af02-8f691650ed76",
      "metadata": {
        "id": "5a3d01a3-02fe-47fc-af02-8f691650ed76"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts.chat import (\n",
        "    ChatPromptTemplate,\n",
        "    SystemMessagePromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae3393eb-4651-44ad-9695-312595e5f004",
      "metadata": {
        "id": "ae3393eb-4651-44ad-9695-312595e5f004"
      },
      "outputs": [],
      "source": [
        "def get_qa_chain(memory):\n",
        "\n",
        "  retriever = db.as_retriever(search_type=\"mmr\",\n",
        "      search_kwargs={\"k\": 2, \"fetch_k\":5}\n",
        "  )\n",
        "  qa_chain = ConversationalRetrievalChain.from_llm(\n",
        "        llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0.2, max_tokens=1000),\n",
        "        retriever=retriever,\n",
        "        memory=memory,\n",
        "        return_source_documents=True\n",
        "    )\n",
        "  sys_prompt = \"Answer the question based on the context provided.\"\n",
        "  qa_chain.combine_docs_chain.llm_chain.prompt.messages[0] = SystemMessagePromptTemplate.from_template(sys_prompt)\n",
        "  #print(f\"qa chain: {qa_chain}\")\n",
        "  return qa_chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41c5b271-faeb-4a3a-b1f1-9f37391351aa",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "a0a2ae87cb2e45cc8eab389988ebcaf0",
            "f574dc3497684b35b83d156afcc0db3c"
          ]
        },
        "id": "41c5b271-faeb-4a3a-b1f1-9f37391351aa",
        "outputId": "9bd64ad3-dbfb-4129-9bbf-e1afbaafb0e8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "calculating scores...\n",
            "computing bert embedding.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a0a2ae87cb2e45cc8eab389988ebcaf0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "computing greedy matching.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f574dc3497684b35b83d156afcc0db3c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done in 0.09 seconds, 10.60 sentences/sec\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'precision': 0.9228496551513672,\n",
              " 'recall': 0.9183753728866577,\n",
              " 'f1': 0.9206070303916931}"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# prompt: write python code to quantitatively compare human written summary with LLM generated summary using BERTScore\n",
        "\n",
        "from bert_score import score\n",
        "\n",
        "def compare_summaries(human_summary, llm_summary):\n",
        "  \"\"\"\n",
        "  Quantitatively compares a human-written summary with an LLM-generated summary using BERTScore.\n",
        "\n",
        "  Args:\n",
        "    human_summary: The human-written summary (string).\n",
        "    llm_summary: The LLM-generated summary (string).\n",
        "\n",
        "  Returns:\n",
        "    A dictionary containing the BERTScore precision, recall, and F1 score.\n",
        "  \"\"\"\n",
        "  P, R, F1 = score([human_summary], [llm_summary], lang=\"en\", verbose=True)\n",
        "  return {\"precision\": P.mean().item(), \"recall\": R.mean().item(), \"f1\": F1.mean().item()}\n",
        "\n",
        "# Example usage\n",
        "human_summary = \"This is a great summary written by a human.\"\n",
        "llm_summary = \"This is a good summary generated by an LLM.\"\n",
        "\n",
        "results = compare_summaries(human_summary, llm_summary)\n",
        "results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8bf07bdc-9dcd-4f51-8554-e7d8b67fec16",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "a33289903f424b4189c4ef7175bdf4cf",
            "c3b4d9ae19cd4818a33a1dec6aeb1de2",
            "a6d4706c12694e719cef318ee3c7fc4a",
            "8bfcd530e37a4d28a9c64784eab21913",
            "3e0dfa5f75e042d0ac6171400a57fe29",
            "3d07814c22a241f49e823f2d5e165cda",
            "87898b6b42984eb998693be6a7068bc3",
            "f4c83afd66314ba5bf9394c43a20d9e9",
            "e2e5cacd38484222bc327f153a160694",
            "646fe4afa5c94230b56227ba9638804a",
            "34174378cd584932a1d3024388dd42f7",
            "60b45e93ef414cc79ee422306f111f1d",
            "45711063693940129dce4b8dd2824617",
            "1585534a485147a387e74add6cc0a843",
            "0aa136cc459740aebc8856d01b91b166",
            "888fdce94ccc4f339531c44ec3b3f1bc",
            "fdf8eed8dfdf4edf9d78e72bd15caeb9",
            "8b864301d81e45d693567e8ac25f4fb4",
            "1201b22338f84595938fe961bcdf71fc",
            "0fd0ea0725ed4e62848f5b6e5e7ad31e"
          ]
        },
        "id": "8bf07bdc-9dcd-4f51-8554-e7d8b67fec16",
        "outputId": "1971271a-a06d-4107-8b60-82016c048dfb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating and comparing summaries:   0%|          | 0/10 [00:00<?, ?it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "calculating scores...\n",
            "computing bert embedding.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a33289903f424b4189c4ef7175bdf4cf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "computing greedy matching.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c3b4d9ae19cd4818a33a1dec6aeb1de2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating and comparing summaries:  10%|█         | 1/10 [00:02<00:21,  2.37s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done in 0.07 seconds, 13.37 sentences/sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "calculating scores...\n",
            "computing bert embedding.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a6d4706c12694e719cef318ee3c7fc4a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "computing greedy matching.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8bfcd530e37a4d28a9c64784eab21913",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating and comparing summaries:  20%|██        | 2/10 [00:04<00:17,  2.16s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done in 0.05 seconds, 19.14 sentences/sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "calculating scores...\n",
            "computing bert embedding.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3e0dfa5f75e042d0ac6171400a57fe29",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "computing greedy matching.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3d07814c22a241f49e823f2d5e165cda",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating and comparing summaries:  30%|███       | 3/10 [00:07<00:16,  2.39s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done in 0.05 seconds, 19.39 sentences/sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "calculating scores...\n",
            "computing bert embedding.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "87898b6b42984eb998693be6a7068bc3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "computing greedy matching.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f4c83afd66314ba5bf9394c43a20d9e9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating and comparing summaries:  40%|████      | 4/10 [00:09<00:14,  2.34s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done in 0.07 seconds, 13.73 sentences/sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "calculating scores...\n",
            "computing bert embedding.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e2e5cacd38484222bc327f153a160694",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "computing greedy matching.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "646fe4afa5c94230b56227ba9638804a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating and comparing summaries:  50%|█████     | 5/10 [00:11<00:11,  2.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done in 0.06 seconds, 17.29 sentences/sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "calculating scores...\n",
            "computing bert embedding.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "34174378cd584932a1d3024388dd42f7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "computing greedy matching.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "60b45e93ef414cc79ee422306f111f1d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating and comparing summaries:  60%|██████    | 6/10 [00:14<00:10,  2.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done in 0.06 seconds, 17.63 sentences/sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "calculating scores...\n",
            "computing bert embedding.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "45711063693940129dce4b8dd2824617",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "computing greedy matching.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1585534a485147a387e74add6cc0a843",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating and comparing summaries:  70%|███████   | 7/10 [00:16<00:07,  2.43s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done in 0.06 seconds, 17.51 sentences/sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "calculating scores...\n",
            "computing bert embedding.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0aa136cc459740aebc8856d01b91b166",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "computing greedy matching.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "888fdce94ccc4f339531c44ec3b3f1bc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating and comparing summaries:  80%|████████  | 8/10 [00:19<00:05,  2.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done in 0.05 seconds, 18.56 sentences/sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "calculating scores...\n",
            "computing bert embedding.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fdf8eed8dfdf4edf9d78e72bd15caeb9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "computing greedy matching.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8b864301d81e45d693567e8ac25f4fb4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating and comparing summaries:  90%|█████████ | 9/10 [00:22<00:02,  2.51s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done in 0.05 seconds, 18.26 sentences/sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "calculating scores...\n",
            "computing bert embedding.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1201b22338f84595938fe961bcdf71fc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "computing greedy matching.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0fd0ea0725ed4e62848f5b6e5e7ad31e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating and comparing summaries: 100%|██████████| 10/10 [00:25<00:00,  2.54s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done in 0.07 seconds, 14.66 sentences/sec\n",
            "       description_id  precision     recall         f1\n",
            "count        10.00000  10.000000  10.000000  10.000000\n",
            "mean          4.50000   0.853120   0.850752   0.851839\n",
            "std           3.02765   0.024358   0.013394   0.017225\n",
            "min           0.00000   0.809282   0.829802   0.819934\n",
            "25%           2.25000   0.850576   0.843224   0.852082\n",
            "50%           4.50000   0.859265   0.855828   0.858666\n",
            "75%           6.75000   0.863572   0.858161   0.860647\n",
            "max           9.00000   0.883153   0.871202   0.869998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "def generate_summary(text):\n",
        "    llm = ChatOpenAI(temperature=0.2, model_name=\"gpt-4o-mini\", max_tokens=128) # or gpt-4 if available\n",
        "\n",
        "    prompt_template = \"\"\"Summarize: {text}\n",
        "    \"\"\"\n",
        "    prompt = PromptTemplate(template=prompt_template, input_variables=[\"text\"])\n",
        "\n",
        "    summary = llm(prompt.format(text=text))\n",
        "    return summary.content\n",
        "\n",
        "def generate_and_compare_summaries(dataset, num_samples=10):\n",
        "    \"\"\"\n",
        "    Generates summaries for a given number of text descriptions using ChatOpenAI's GPT-4o-mini,\n",
        "    compares them with the respective abstracts using BERTScore, and returns statistics.\n",
        "    \"\"\"\n",
        "\n",
        "    results = []\n",
        "    for i in tqdm(range(num_samples), desc=\"Generating and comparing summaries\"):\n",
        "      description = dataset[\"description\"][i]\n",
        "      abstract = dataset[\"abstract\"][i]\n",
        "\n",
        "      try:\n",
        "        # Generate summary (replace with your GPT-4o-mini call)\n",
        "        llm_summary = generate_summary(description)\n",
        "\n",
        "        # Compare summaries\n",
        "        metrics = compare_summaries(abstract, llm_summary)\n",
        "        results.append({\n",
        "          \"description_id\": i,\n",
        "          \"precision\": metrics[\"precision\"],\n",
        "          \"recall\": metrics[\"recall\"],\n",
        "          \"f1\": metrics[\"f1\"]\n",
        "      })\n",
        "      except Exception as e:\n",
        "        print(f\"Error processing sample {i}: {e}\")\n",
        "        results.append({\n",
        "          \"description_id\": i,\n",
        "          \"precision\": None,  # Indicate error with None\n",
        "          \"recall\": None,\n",
        "          \"f1\": None\n",
        "        })\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "\n",
        "# Example usage:\n",
        "summary_results = generate_and_compare_summaries(dataset)\n",
        "\n",
        "print(summary_results.describe()) # Prints statistics for precision, recall, and F1 score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1992fa41-5b51-4ca9-b262-0d7aba7411de",
      "metadata": {
        "id": "1992fa41-5b51-4ca9-b262-0d7aba7411de"
      },
      "outputs": [],
      "source": [
        "def get_retrieved_docs_metadata(result):\n",
        "    # Get metadata of retrieved documents\n",
        "    retrieved_docs_metadata = \"\"\n",
        "    if 'source_documents' in result:\n",
        "        for doc in result['source_documents']:\n",
        "            if hasattr(doc, 'metadata'):\n",
        "                retrieved_docs_metadata += f\"Metadata: {doc.metadata}\\n\"\n",
        "    return retrieved_docs_metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3771aeb3-88fd-4f9c-9636-d97ede018d8d",
      "metadata": {
        "id": "3771aeb3-88fd-4f9c-9636-d97ede018d8d"
      },
      "outputs": [],
      "source": [
        "  prior_art_memory = ConversationBufferWindowMemory(\n",
        "                    memory_key=\"chat_history\",\n",
        "                    return_messages=True,\n",
        "                    k=3,\n",
        "                    output_key='answer'\n",
        "        )\n",
        "\n",
        "def prior_art_search(query):\n",
        "    qa_chain = get_qa_chain(prior_art_memory)\n",
        "    result = qa_chain({\"question\": query})\n",
        "    retrieved_docs_metadata = get_retrieved_docs_metadata(result)\n",
        "    print(\"result: \", result)\n",
        "    return (result[\"answer\"], retrieved_docs_metadata)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7eb8e0ae-4111-4717-8901-e0e0deb1d0c7",
      "metadata": {
        "id": "7eb8e0ae-4111-4717-8901-e0e0deb1d0c7"
      },
      "outputs": [],
      "source": [
        "patent_summarization_memory = ConversationBufferWindowMemory(\n",
        "    memory_key=\"chat_history\",\n",
        "    return_messages=True,\n",
        "    k=3,\n",
        "    output_key='answer'\n",
        ")\n",
        "\n",
        "def patent_summarization(patent_text):\n",
        "    qa_chain = get_qa_chain(patent_summarization_memory)\n",
        "    result = qa_chain({\"question\": f\"Summarize this patent:\\n{patent_text}\"})\n",
        "    retrieved_docs_metadata = get_retrieved_docs_metadata(result)\n",
        "    return (result[\"answer\"], retrieved_docs_metadata)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0aa88d21-93de-41f7-92fb-69a79031403d",
      "metadata": {
        "id": "0aa88d21-93de-41f7-92fb-69a79031403d"
      },
      "outputs": [],
      "source": [
        "competitive_monitoring_memory = ConversationBufferWindowMemory(\n",
        "    memory_key=\"chat_history\",\n",
        "    return_messages=True,\n",
        "    k=3,\n",
        "    output_key='answer'\n",
        ")\n",
        "\n",
        "def competitive_monitoring(technology_area):\n",
        "    # Placeholder for filtering by technology area (requires further implementation)\n",
        "    # In a real application, you would filter the dataset or vector database\n",
        "    # based on the provided technology area before retrieval.\n",
        "    qa_chain = get_qa_chain(competitive_monitoring_memory)\n",
        "    result = qa_chain({\"question\": f\"Summarize recent patents in {technology_area}\"})\n",
        "    retrieved_docs_metadata = get_retrieved_docs_metadata(result)\n",
        "    return (result[\"answer\"], retrieved_docs_metadata)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e244508-f206-470b-abf9-6dc3c60249e8",
      "metadata": {
        "id": "8e244508-f206-470b-abf9-6dc3c60249e8"
      },
      "outputs": [],
      "source": [
        "claim_analysis_memory = ConversationBufferWindowMemory(\n",
        "    memory_key=\"chat_history\",\n",
        "    return_messages=True,\n",
        "    k=3,\n",
        "    output_key='answer'\n",
        ")\n",
        "\n",
        "def claim_analysis(claim1, claim2):\n",
        "    qa_chain = get_qa_chain(claim_analysis_memory)\n",
        "    result = qa_chain(\n",
        "        {\n",
        "            \"question\": f\"Compare and contrast these two claims:\\nClaim 1: {claim1}\\nClaim 2: {claim2}\"\n",
        "        }\n",
        "    )\n",
        "    retrieved_docs_metadata = get_retrieved_docs_metadata(result)\n",
        "    return (result[\"answer\"], retrieved_docs_metadata)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb42f885-6f36-4d2f-bf79-ac077ae37b71",
      "metadata": {
        "id": "eb42f885-6f36-4d2f-bf79-ac077ae37b71"
      },
      "outputs": [],
      "source": [
        "landscape_overview_memory = ConversationBufferWindowMemory(\n",
        "    memory_key=\"chat_history\",\n",
        "    return_messages=True,\n",
        "    k=3,\n",
        "    output_key='answer'\n",
        ")\n",
        "\n",
        "def landscape_overview(cpc_code):\n",
        "    # Placeholder for filtering by CPC code (requires further implementation)\n",
        "    cpc_code = 'g'\n",
        "    qa_chain = get_qa_chain(landscape_overview_memory)\n",
        "    result = qa_chain({\"question\": f\"Overview of patent landscape for CPC code {cpc_code}\"})\n",
        "    retrieved_docs_metadata = get_retrieved_docs_metadata(result)\n",
        "    return (result[\"answer\"], retrieved_docs_metadata)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb2d63fa-3931-4b85-8b77-99a83dbb4c3c",
      "metadata": {
        "id": "cb2d63fa-3931-4b85-8b77-99a83dbb4c3c"
      },
      "outputs": [],
      "source": [
        "def clear_memory():\n",
        "\n",
        "    prior_art_memory.clear()\n",
        "    patent_summarization_memory.clear()\n",
        "    competitive_monitoring_memory.clear()\n",
        "    claim_analysis_memory.clear()\n",
        "    landscape_overview_memory.clear()\n",
        "\n",
        "    return \"Memory Cleared !\", \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d979f03a-204b-4ecf-864c-85e8608eff9e",
      "metadata": {
        "id": "d979f03a-204b-4ecf-864c-85e8608eff9e"
      },
      "outputs": [],
      "source": [
        "# Query Examples (replace with your actual examples if needed)\n",
        "prior_art_suggestions = [\n",
        "    \"Method for measuring the gravitational field of a celestial body\",\n",
        "    \"System for generating high-intensity magnetic fields\",\n",
        "    \"Device for controlling the flow of a fluid in a microfluidic channel\"\n",
        "]\n",
        "\n",
        "monitoring_suggestions = [  # G-specific examples\n",
        "    \"Advancements in optical metrology for semiconductor manufacturing\",\n",
        "    \"Trends in nuclear fusion reactor design\",\n",
        "    \"Developments in acoustic sensing for medical imaging\"\n",
        "]\n",
        "\n",
        "claim_suggestions = [ # G-specific examples\n",
        "    [\"Claim 1: A method for measuring the speed of light using interferometry.\", \"Claim 2: A method for determining the refractive index of a material using interferometry.\"],\n",
        "    [\"Claim 1: A device for generating acoustic waves using piezoelectric materials.\",\"Claim 2: A device for generating acoustic waves using magnetostrictive materials.\"],\n",
        "    [\"Claim 1: A system for controlling the temperature of a superconducting magnet.\", \"Claim 2: A system for controlling the magnetic field strength of a superconducting magnet.\"]\n",
        "]\n",
        "\n",
        "\n",
        "summary_suggestions = [ # G-specific examples\n",
        "    \"Patent on a new type of optical sensor for detecting gravitational waves\",\n",
        "    \"Patent on an improved design for a nuclear fusion reactor\",\n",
        "    \"Patent on a novel method for measuring the viscosity of fluids using microfluidic devices\"\n",
        "]\n",
        "\n",
        "landscape_suggestions = [ # G-specific examples\n",
        "    \"CPC code: G01N (Measuring instruments; Measuring methods in general)\",\n",
        "    \"CPC code: G21B (Nuclear reactors; accessories or details thereof)\",\n",
        "    \"CPC code: G02B (Optical elements, systems, or apparatus)\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e03b35bb-3668-48de-9046-cbd7fed0bda1",
      "metadata": {
        "scrolled": true,
        "id": "e03b35bb-3668-48de-9046-cbd7fed0bda1",
        "outputId": "28cd077c-0bbb-430d-b057-72adada670ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "* Running on local URL:  http://127.0.0.1:7860\n",
            "* Running on public URL: https://733151c3dee1074997.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://733151c3dee1074997.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://733151c3dee1074997.gradio.live\n"
          ]
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# BigPatent Multi-Use-Case App\")\n",
        "\n",
        "    with gr.Tab(\"Prior Art Search\"):\n",
        "        prior_art_inputs = gr.Textbox(lines=2, placeholder=\"Enter your invention description...\")\n",
        "\n",
        "        prior_art_examples = gr.Examples(prior_art_suggestions, prior_art_inputs) # Query suggestions\n",
        "        prior_art_outputs = [gr.Textbox(lines=5, label=\"Potential Prior Art\"),\n",
        "                     gr.Textbox(label=\"Document Metadata\")\n",
        "            ]\n",
        "        prior_art_iface = gr.Interface(\n",
        "            fn=prior_art_search,\n",
        "            inputs=prior_art_inputs,\n",
        "            outputs=prior_art_outputs\n",
        "        )\n",
        "        clear_button_prior_art = gr.Button(\"Clear History\")\n",
        "        clear_button_prior_art.click(clear_memory, [], prior_art_outputs) # Update outputs\n",
        "\n",
        "    with gr.Tab(\"Competitive Monitoring\"):\n",
        "        monitoring_inputs = gr.Textbox(placeholder=\"Enter technology area\")\n",
        "        monitoring_examples = gr.Examples(monitoring_suggestions, monitoring_inputs) # Query suggestions\n",
        "        monitoring_outputs = [gr.Textbox(lines=5, label=\"Competitive Landscape\"),\n",
        "                     gr.Textbox(label=\"Document Metadata\")\n",
        "            ]\n",
        "        monitoring_iface = gr.Interface(\n",
        "            fn=competitive_monitoring,\n",
        "            inputs=monitoring_inputs,\n",
        "            outputs=monitoring_outputs\n",
        "        )\n",
        "        clear_button_monitoring = gr.Button(\"Clear History\")\n",
        "        clear_button_monitoring.click(clear_memory, [], monitoring_outputs) # Update outputs\n",
        "\n",
        "    with gr.Tab(\"Claim Analysis\"):\n",
        "        claim_inputs = [\n",
        "                gr.Textbox(lines=2, placeholder=\"Enter claim 1\"),\n",
        "                gr.Textbox(lines=2, placeholder=\"Enter claim 2\"),\n",
        "            ]\n",
        "        claim_examples = gr.Examples(claim_suggestions, claim_inputs) # Query suggestions\n",
        "        claim_outputs = [gr.Textbox(lines=5, label=\"Claim Comparison\"),\n",
        "                     gr.Textbox(label=\"Document Metadata\")\n",
        "            ]\n",
        "        claim_iface = gr.Interface(\n",
        "            fn=claim_analysis,\n",
        "            inputs=claim_inputs,\n",
        "            outputs=claim_outputs\n",
        "        )\n",
        "        clear_button_claim = gr.Button(\"Clear History\")\n",
        "        clear_button_claim.click(clear_memory, [], claim_outputs) # Update outputs\n",
        "\n",
        "    with gr.Tab(\"Patent Summarization\"):\n",
        "        summary_inputs = gr.Textbox(lines=5, placeholder=\"Enter patent text\")\n",
        "        summary_examples = gr.Examples(summary_suggestions, summary_inputs) # Query suggestions\n",
        "        summary_outputs = [gr.Textbox(lines=3, label=\"Patent Summary\"),\n",
        "                     gr.Textbox(label=\"Document Metadata\")\n",
        "            ]\n",
        "        summary_iface = gr.Interface(\n",
        "            fn=patent_summarization,\n",
        "            inputs=summary_inputs,\n",
        "            outputs=summary_outputs\n",
        "        )\n",
        "        clear_button_summary = gr.Button(\"Clear History\")\n",
        "        clear_button_summary.click(clear_memory, [], summary_outputs) # Update outputs\n",
        "\n",
        "    with gr.Tab(\"Landscape Overview\"):\n",
        "        landscape_inputs = gr.Textbox(placeholder=\"Enter CPC code\")\n",
        "        ladscape_examples = gr.Examples(landscape_suggestions, landscape_inputs) # Query suggestions\n",
        "        landscape_outputs = [gr.Textbox(lines=5, label=\"Landscape Overview\"),\n",
        "                     gr.Textbox(label=\"Document Metadata\")\n",
        "            ]\n",
        "        landscape_iface = gr.Interface(\n",
        "            fn=landscape_overview,\n",
        "            inputs=landscape_inputs,\n",
        "            outputs=landscape_outputs\n",
        "        )\n",
        "        clear_button_landscape = gr.Button(\"Clear History\")\n",
        "        clear_button_landscape.click(clear_memory, [], summary_outputs) # Update outputs\n",
        "\n",
        "demo.launch(share=True, debug=True)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}